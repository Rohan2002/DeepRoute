{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import os\\nimport warnings\\nimport platform\\nimport tensorflow as tf\\nfrom object_detection.utils import config_util\\nfrom object_detection.protos import pipeline_pb2\\nfrom google.protobuf import text_format\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n%load_ext autoreload\\n%autoreload 2\\n\\n%reload_ext nb_black\\n%config IPCompleter.greedy=True\";\n",
       "                var nbb_formatted_code = \"import os\\nimport warnings\\nimport platform\\nimport tensorflow as tf\\nfrom object_detection.utils import config_util\\nfrom object_detection.protos import pipeline_pb2\\nfrom google.protobuf import text_format\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n%load_ext autoreload\\n%autoreload 2\\n\\n%reload_ext nb_black\\n%config IPCompleter.greedy=True\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import platform\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%reload_ext nb_black\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"# /home/ryd4/DeepRoute/protoc/bin/protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . --user\";\n",
       "                var nbb_formatted_code = \"# /home/ryd4/DeepRoute/protoc/bin/protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . --user\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# /home/ryd4/DeepRoute/protoc/bin/protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"CUSTOM_MODEL_NAME = \\\"my_ssd_mobnet\\\"\\nPRETRAINED_MODEL_NAME = \\\"ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\\\"\\nPRETRAINED_MODEL = \\\"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\\\"\\nTF_RECORD_SCRIPT_NAME = \\\"generate_tfrecord.py\\\"\\nLABEL_MAP_NAME = \\\"label_map.pbtxt\\\"\\ncurrent_os = platform.system()\";\n",
       "                var nbb_formatted_code = \"CUSTOM_MODEL_NAME = \\\"my_ssd_mobnet\\\"\\nPRETRAINED_MODEL_NAME = \\\"ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\\\"\\nPRETRAINED_MODEL = \\\"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\\\"\\nTF_RECORD_SCRIPT_NAME = \\\"generate_tfrecord.py\\\"\\nLABEL_MAP_NAME = \\\"label_map.pbtxt\\\"\\ncurrent_os = platform.system()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CUSTOM_MODEL_NAME = \"my_ssd_mobnet\"\n",
    "PRETRAINED_MODEL_NAME = \"ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\"\n",
    "PRETRAINED_MODEL = \"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\"\n",
    "TF_RECORD_SCRIPT_NAME = \"generate_tfrecord.py\"\n",
    "LABEL_MAP_NAME = \"label_map.pbtxt\"\n",
    "current_os = platform.system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"labels = [{\\\"name\\\": \\\"parent-mice\\\", \\\"id\\\": 1}, {\\\"name\\\": \\\"child-mice\\\", \\\"id\\\": 2}]\";\n",
       "                var nbb_formatted_code = \"labels = [{\\\"name\\\": \\\"parent-mice\\\", \\\"id\\\": 1}, {\\\"name\\\": \\\"child-mice\\\", \\\"id\\\": 2}]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = [{\"name\": \"parent-mice\", \"id\": 1}, {\"name\": \"child-mice\", \"id\": 2}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"parent_directory = os.path.dirname(os.getcwd())\\npaths = {\\n    \\\"SRC_PATH\\\": os.path.join(parent_directory, \\\"src\\\"),\\n    \\\"DATA_PATH\\\": os.path.join(parent_directory, \\\"data\\\"),\\n    \\\"APIMODEL_PATH\\\": os.path.join(parent_directory, \\\"api_models\\\"),\\n    \\\"MODEL_PATH\\\": os.path.join(parent_directory, \\\"my_models\\\"),\\n    \\\"PRETRAINED_MODEL_PATH\\\": os.path.join(parent_directory, \\\"pre-trained-models\\\"),\\n    \\\"CHECKPOINT_PATH\\\": os.path.join(parent_directory, \\\"my_models\\\", CUSTOM_MODEL_NAME),\\n    \\\"OUTPUT_PATH\\\": os.path.join(\\n        parent_directory, \\\"my_models\\\", CUSTOM_MODEL_NAME, \\\"export\\\"\\n    ),\\n    \\\"TFJS_PATH\\\": os.path.join(\\n        parent_directory, \\\"my_models\\\", CUSTOM_MODEL_NAME, \\\"tfjsexport\\\"\\n    ),\\n    \\\"TFLITE_PATH\\\": os.path.join(\\n        parent_directory, \\\"my_models\\\", CUSTOM_MODEL_NAME, \\\"tfliteexport\\\"\\n    ),\\n    \\\"PROTOC_PATH\\\": os.path.join(parent_directory, \\\"protoc\\\"),\\n}\";\n",
       "                var nbb_formatted_code = \"parent_directory = os.path.dirname(os.getcwd())\\npaths = {\\n    \\\"SRC_PATH\\\": os.path.join(parent_directory, \\\"src\\\"),\\n    \\\"DATA_PATH\\\": os.path.join(parent_directory, \\\"data\\\"),\\n    \\\"APIMODEL_PATH\\\": os.path.join(parent_directory, \\\"api_models\\\"),\\n    \\\"MODEL_PATH\\\": os.path.join(parent_directory, \\\"my_models\\\"),\\n    \\\"PRETRAINED_MODEL_PATH\\\": os.path.join(parent_directory, \\\"pre-trained-models\\\"),\\n    \\\"CHECKPOINT_PATH\\\": os.path.join(parent_directory, \\\"my_models\\\", CUSTOM_MODEL_NAME),\\n    \\\"OUTPUT_PATH\\\": os.path.join(\\n        parent_directory, \\\"my_models\\\", CUSTOM_MODEL_NAME, \\\"export\\\"\\n    ),\\n    \\\"TFJS_PATH\\\": os.path.join(\\n        parent_directory, \\\"my_models\\\", CUSTOM_MODEL_NAME, \\\"tfjsexport\\\"\\n    ),\\n    \\\"TFLITE_PATH\\\": os.path.join(\\n        parent_directory, \\\"my_models\\\", CUSTOM_MODEL_NAME, \\\"tfliteexport\\\"\\n    ),\\n    \\\"PROTOC_PATH\\\": os.path.join(parent_directory, \\\"protoc\\\"),\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parent_directory = os.path.dirname(os.getcwd())\n",
    "paths = {\n",
    "    \"SRC_PATH\": os.path.join(parent_directory, \"src\"),\n",
    "    \"DATA_PATH\": os.path.join(parent_directory, \"data\"),\n",
    "    \"APIMODEL_PATH\": os.path.join(parent_directory, \"api_models\"),\n",
    "    \"MODEL_PATH\": os.path.join(parent_directory, \"my_models\"),\n",
    "    \"PRETRAINED_MODEL_PATH\": os.path.join(parent_directory, \"pre-trained-models\"),\n",
    "    \"CHECKPOINT_PATH\": os.path.join(parent_directory, \"my_models\", CUSTOM_MODEL_NAME),\n",
    "    \"OUTPUT_PATH\": os.path.join(\n",
    "        parent_directory, \"my_models\", CUSTOM_MODEL_NAME, \"export\"\n",
    "    ),\n",
    "    \"TFJS_PATH\": os.path.join(\n",
    "        parent_directory, \"my_models\", CUSTOM_MODEL_NAME, \"tfjsexport\"\n",
    "    ),\n",
    "    \"TFLITE_PATH\": os.path.join(\n",
    "        parent_directory, \"my_models\", CUSTOM_MODEL_NAME, \"tfliteexport\"\n",
    "    ),\n",
    "    \"PROTOC_PATH\": os.path.join(parent_directory, \"protoc\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"files = {\\n    \\\"PIPELINE_CONFIG\\\": os.path.join(\\n        parent_directory, \\\"my_models\\\", CUSTOM_MODEL_NAME, \\\"pipeline.config\\\"\\n    ),\\n    \\\"TF_RECORD_SCRIPT\\\": os.path.join(paths[\\\"DATA_PATH\\\"], TF_RECORD_SCRIPT_NAME),\\n    \\\"LABELMAP\\\": os.path.join(paths[\\\"DATA_PATH\\\"], LABEL_MAP_NAME),\\n}\";\n",
       "                var nbb_formatted_code = \"files = {\\n    \\\"PIPELINE_CONFIG\\\": os.path.join(\\n        parent_directory, \\\"my_models\\\", CUSTOM_MODEL_NAME, \\\"pipeline.config\\\"\\n    ),\\n    \\\"TF_RECORD_SCRIPT\\\": os.path.join(paths[\\\"DATA_PATH\\\"], TF_RECORD_SCRIPT_NAME),\\n    \\\"LABELMAP\\\": os.path.join(paths[\\\"DATA_PATH\\\"], LABEL_MAP_NAME),\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files = {\n",
    "    \"PIPELINE_CONFIG\": os.path.join(\n",
    "        parent_directory, \"my_models\", CUSTOM_MODEL_NAME, \"pipeline.config\"\n",
    "    ),\n",
    "    \"TF_RECORD_SCRIPT\": os.path.join(paths[\"DATA_PATH\"], TF_RECORD_SCRIPT_NAME),\n",
    "    \"LABELMAP\": os.path.join(paths[\"DATA_PATH\"], LABEL_MAP_NAME),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"for path in paths.values():\\n    if not os.path.exists(path):\\n        if os.name == \\\"posix\\\":\\n            !mkdir -p {path}\\n        if os.name == \\\"nt\\\":\\n            !mkdir {path}\";\n",
       "                var nbb_formatted_code = \"for path in paths.values():\\n    if not os.path.exists(path):\\n        if os.name == \\\"posix\\\":\\n            !mkdir -p {path}\\n        if os.name == \\\"nt\\\":\\n            !mkdir {path}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == \"posix\":\n",
    "            !mkdir -p {path}\n",
    "        if os.name == \"nt\":\n",
    "            !mkdir {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'models' already exists and is not an empty directory.\r\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"if not os.path.exists(\\n    os.path.join(paths[\\\"APIMODEL_PATH\\\"], \\\"research\\\", \\\"object_detection\\\")\\n):\\n    !cd {paths['APIMODEL_PATH']} && module load git && git clone https://github.com/tensorflow/models\";\n",
       "                var nbb_formatted_code = \"if not os.path.exists(\\n    os.path.join(paths[\\\"APIMODEL_PATH\\\"], \\\"research\\\", \\\"object_detection\\\")\\n):\\n    !cd {paths['APIMODEL_PATH']} && module load git && git clone https://github.com/tensorflow/models\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not os.path.exists(\n",
    "    os.path.join(paths[\"APIMODEL_PATH\"], \"research\", \"object_detection\")\n",
    "):\n",
    "    !cd {paths['APIMODEL_PATH']} && module load git && git clone https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-07-02 00:44:53--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 172.217.7.16, 2607:f8b0:4006:800::2010\n",
      "Connecting to download.tensorflow.org (download.tensorflow.org)|172.217.7.16|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 20515344 (20M) [application/x-tar]\n",
      "Saving to: ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’\n",
      "\n",
      "100%[======================================>] 20,515,344  63.7MB/s   in 0.3s   \n",
      "\n",
      "2021-07-02 00:44:53 (63.7 MB/s) - ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’ saved [20515344/20515344]\n",
      "\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"download_model = True\\nif download_model and os.name == \\\"posix\\\":\\n    !wget {PRETRAINED_MODEL}\\n    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\\n    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\\nif download_model and os.name == \\\"nt\\\":\\n    !wget.download(PRETRAINED_MODEL)\\n    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\\n    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\";\n",
       "                var nbb_formatted_code = \"download_model = True\\nif download_model and os.name == \\\"posix\\\":\\n    !wget {PRETRAINED_MODEL}\\n    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\\n    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\\nif download_model and os.name == \\\"nt\\\":\\n    !wget.download(PRETRAINED_MODEL)\\n    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\\n    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "download_model = True\n",
    "if download_model and os.name == \"posix\":\n",
    "    !wget {PRETRAINED_MODEL}\n",
    "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
    "if download_model and os.name == \"nt\":\n",
    "    !wget.download(PRETRAINED_MODEL)\n",
    "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"# # Install Tensorflow Object Detection\\n# if current_os == \\\"Linux\\\":\\n#     !apt-get install protobuf-compiler\\n#     !cd {f'{paths['APIMODEL_PATH']}/models/research'} && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install {.}\\n# if current_os == \\\"Windows\\\":\\n#     url = \\\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\\\"\\n#     wget.download(url)\\n#     !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\\n#     !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\\n#     os.environ[\\\"PATH\\\"] += os.pathsep + os.path.abspath(\\n#         os.path.join(paths[\\\"PROTOC_PATH\\\"], \\\"bin\\\")\\n#     )\\n#     !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\\\\\packages\\\\\\\\tf2\\\\\\\\setup.py setup.py && python setup.py build && python setup.py install\\n#     !cd Tensorflow/models/research/slim && pip install -e {.}\\n# if current_os == \\\"Darwin\\\":\\n#     api_model = f'{paths[\\\"APIMODEL_PATH\\\"]}/models/research'\\n#     #!brew install protobuf-compiler\\n#     # !cd {api_model} && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install .\";\n",
       "                var nbb_formatted_code = \"# # Install Tensorflow Object Detection\\n# if current_os == \\\"Linux\\\":\\n#     !apt-get install protobuf-compiler\\n#     !cd {f'{paths['APIMODEL_PATH']}/models/research'} && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install {.}\\n# if current_os == \\\"Windows\\\":\\n#     url = \\\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\\\"\\n#     wget.download(url)\\n#     !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\\n#     !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\\n#     os.environ[\\\"PATH\\\"] += os.pathsep + os.path.abspath(\\n#         os.path.join(paths[\\\"PROTOC_PATH\\\"], \\\"bin\\\")\\n#     )\\n#     !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\\\\\packages\\\\\\\\tf2\\\\\\\\setup.py setup.py && python setup.py build && python setup.py install\\n#     !cd Tensorflow/models/research/slim && pip install -e {.}\\n# if current_os == \\\"Darwin\\\":\\n#     api_model = f'{paths[\\\"APIMODEL_PATH\\\"]}/models/research'\\n#     #!brew install protobuf-compiler\\n#     # !cd {api_model} && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install .\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Install Tensorflow Object Detection\n",
    "# if current_os == \"Linux\":\n",
    "#     !apt-get install protobuf-compiler\n",
    "#     !cd {f'{paths['APIMODEL_PATH']}/models/research'} && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install {.}\n",
    "# if current_os == \"Windows\":\n",
    "#     url = \"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
    "#     wget.download(url)\n",
    "#     !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
    "#     !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
    "#     os.environ[\"PATH\"] += os.pathsep + os.path.abspath(\n",
    "#         os.path.join(paths[\"PROTOC_PATH\"], \"bin\")\n",
    "#     )\n",
    "#     !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
    "#     !cd Tensorflow/models/research/slim && pip install -e {.}\n",
    "# if current_os == \"Darwin\":\n",
    "#     api_model = f'{paths[\"APIMODEL_PATH\"]}/models/research'\n",
    "#     #!brew install protobuf-compiler\n",
    "#     # !cd {api_model} && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"path_to_train = f'{paths[\\\"DATA_PATH\\\"]}/train'\\npath_to_test = f'{paths[\\\"DATA_PATH\\\"]}/test'\\npath_to_labels = f'{paths[\\\"DATA_PATH\\\"]}/{LABEL_MAP_NAME}'\";\n",
       "                var nbb_formatted_code = \"path_to_train = f'{paths[\\\"DATA_PATH\\\"]}/train'\\npath_to_test = f'{paths[\\\"DATA_PATH\\\"]}/test'\\npath_to_labels = f'{paths[\\\"DATA_PATH\\\"]}/{LABEL_MAP_NAME}'\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_to_train = f'{paths[\"DATA_PATH\"]}/train'\n",
    "path_to_test = f'{paths[\"DATA_PATH\"]}/test'\n",
    "path_to_labels = f'{paths[\"DATA_PATH\"]}/{LABEL_MAP_NAME}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"# !python3 generate_tfrecord.py -x {path_to_train} -l {path_to_labels} -o {os.path.join(paths[\\\"DATA_PATH\\\"], 'train.record')}\\n# !python3 generate_tfrecord.py -x {path_to_test} -l {path_to_labels} -o {os.path.join(paths[\\\"DATA_PATH\\\"], 'test.record')}\";\n",
       "                var nbb_formatted_code = \"# !python3 generate_tfrecord.py -x {path_to_train} -l {path_to_labels} -o {os.path.join(paths[\\\"DATA_PATH\\\"], 'train.record')}\\n# !python3 generate_tfrecord.py -x {path_to_test} -l {path_to_labels} -o {os.path.join(paths[\\\"DATA_PATH\\\"], 'test.record')}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# !python3 generate_tfrecord.py -x {path_to_train} -l {path_to_labels} -o {os.path.join(paths[\"DATA_PATH\"], 'train.record')}\n",
    "# !python3 generate_tfrecord.py -x {path_to_test} -l {path_to_labels} -o {os.path.join(paths[\"DATA_PATH\"], 'test.record')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"if os.name == \\\"posix\\\":\\n    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\\nif os.name == \\\"nt\\\":\\n    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\";\n",
       "                var nbb_formatted_code = \"if os.name == \\\"posix\\\":\\n    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\\nif os.name == \\\"nt\\\":\\n    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if os.name == \"posix\":\n",
    "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
    "if os.name == \"nt\":\n",
    "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': ssd {\n",
       "   num_classes: 90\n",
       "   image_resizer {\n",
       "     fixed_shape_resizer {\n",
       "       height: 320\n",
       "       width: 320\n",
       "     }\n",
       "   }\n",
       "   feature_extractor {\n",
       "     type: \"ssd_mobilenet_v2_fpn_keras\"\n",
       "     depth_multiplier: 1.0\n",
       "     min_depth: 16\n",
       "     conv_hyperparams {\n",
       "       regularizer {\n",
       "         l2_regularizer {\n",
       "           weight: 3.9999998989515007e-05\n",
       "         }\n",
       "       }\n",
       "       initializer {\n",
       "         random_normal_initializer {\n",
       "           mean: 0.0\n",
       "           stddev: 0.009999999776482582\n",
       "         }\n",
       "       }\n",
       "       activation: RELU_6\n",
       "       batch_norm {\n",
       "         decay: 0.996999979019165\n",
       "         scale: true\n",
       "         epsilon: 0.0010000000474974513\n",
       "       }\n",
       "     }\n",
       "     use_depthwise: true\n",
       "     override_base_feature_extractor_hyperparams: true\n",
       "     fpn {\n",
       "       min_level: 3\n",
       "       max_level: 7\n",
       "       additional_layer_depth: 128\n",
       "     }\n",
       "   }\n",
       "   box_coder {\n",
       "     faster_rcnn_box_coder {\n",
       "       y_scale: 10.0\n",
       "       x_scale: 10.0\n",
       "       height_scale: 5.0\n",
       "       width_scale: 5.0\n",
       "     }\n",
       "   }\n",
       "   matcher {\n",
       "     argmax_matcher {\n",
       "       matched_threshold: 0.5\n",
       "       unmatched_threshold: 0.5\n",
       "       ignore_thresholds: false\n",
       "       negatives_lower_than_unmatched: true\n",
       "       force_match_for_each_row: true\n",
       "       use_matmul_gather: true\n",
       "     }\n",
       "   }\n",
       "   similarity_calculator {\n",
       "     iou_similarity {\n",
       "     }\n",
       "   }\n",
       "   box_predictor {\n",
       "     weight_shared_convolutional_box_predictor {\n",
       "       conv_hyperparams {\n",
       "         regularizer {\n",
       "           l2_regularizer {\n",
       "             weight: 3.9999998989515007e-05\n",
       "           }\n",
       "         }\n",
       "         initializer {\n",
       "           random_normal_initializer {\n",
       "             mean: 0.0\n",
       "             stddev: 0.009999999776482582\n",
       "           }\n",
       "         }\n",
       "         activation: RELU_6\n",
       "         batch_norm {\n",
       "           decay: 0.996999979019165\n",
       "           scale: true\n",
       "           epsilon: 0.0010000000474974513\n",
       "         }\n",
       "       }\n",
       "       depth: 128\n",
       "       num_layers_before_predictor: 4\n",
       "       kernel_size: 3\n",
       "       class_prediction_bias_init: -4.599999904632568\n",
       "       share_prediction_tower: true\n",
       "       use_depthwise: true\n",
       "     }\n",
       "   }\n",
       "   anchor_generator {\n",
       "     multiscale_anchor_generator {\n",
       "       min_level: 3\n",
       "       max_level: 7\n",
       "       anchor_scale: 4.0\n",
       "       aspect_ratios: 1.0\n",
       "       aspect_ratios: 2.0\n",
       "       aspect_ratios: 0.5\n",
       "       scales_per_octave: 2\n",
       "     }\n",
       "   }\n",
       "   post_processing {\n",
       "     batch_non_max_suppression {\n",
       "       score_threshold: 9.99999993922529e-09\n",
       "       iou_threshold: 0.6000000238418579\n",
       "       max_detections_per_class: 100\n",
       "       max_total_detections: 100\n",
       "       use_static_shapes: false\n",
       "     }\n",
       "     score_converter: SIGMOID\n",
       "   }\n",
       "   normalize_loss_by_num_matches: true\n",
       "   loss {\n",
       "     localization_loss {\n",
       "       weighted_smooth_l1 {\n",
       "       }\n",
       "     }\n",
       "     classification_loss {\n",
       "       weighted_sigmoid_focal {\n",
       "         gamma: 2.0\n",
       "         alpha: 0.25\n",
       "       }\n",
       "     }\n",
       "     classification_weight: 1.0\n",
       "     localization_weight: 1.0\n",
       "   }\n",
       "   encode_background_as_zeros: true\n",
       "   normalize_loc_loss_by_codesize: true\n",
       "   inplace_batchnorm_update: true\n",
       "   freeze_batchnorm: false\n",
       " },\n",
       " 'train_config': batch_size: 128\n",
       " data_augmentation_options {\n",
       "   random_horizontal_flip {\n",
       "   }\n",
       " }\n",
       " data_augmentation_options {\n",
       "   random_crop_image {\n",
       "     min_object_covered: 0.0\n",
       "     min_aspect_ratio: 0.75\n",
       "     max_aspect_ratio: 3.0\n",
       "     min_area: 0.75\n",
       "     max_area: 1.0\n",
       "     overlap_thresh: 0.0\n",
       "   }\n",
       " }\n",
       " sync_replicas: true\n",
       " optimizer {\n",
       "   momentum_optimizer {\n",
       "     learning_rate {\n",
       "       cosine_decay_learning_rate {\n",
       "         learning_rate_base: 0.07999999821186066\n",
       "         total_steps: 50000\n",
       "         warmup_learning_rate: 0.026666000485420227\n",
       "         warmup_steps: 1000\n",
       "       }\n",
       "     }\n",
       "     momentum_optimizer_value: 0.8999999761581421\n",
       "   }\n",
       "   use_moving_average: false\n",
       " }\n",
       " fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
       " num_steps: 50000\n",
       " startup_delay_steps: 0.0\n",
       " replicas_to_aggregate: 8\n",
       " max_number_of_boxes: 100\n",
       " unpad_groundtruth_tensors: false\n",
       " fine_tune_checkpoint_type: \"classification\"\n",
       " fine_tune_checkpoint_version: V2,\n",
       " 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " tf_record_input_reader {\n",
       "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " },\n",
       " 'eval_config': metrics_set: \"coco_detection_metrics\"\n",
       " use_moving_averages: false,\n",
       " 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " shuffle: false\n",
       " num_epochs: 1\n",
       " tf_record_input_reader {\n",
       "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " }\n",
       " ],\n",
       " 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " shuffle: false\n",
       " num_epochs: 1\n",
       " tf_record_input_reader {\n",
       "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " }}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"config = config_util.get_configs_from_pipeline_file(files[\\\"PIPELINE_CONFIG\\\"])\\nconfig\";\n",
       "                var nbb_formatted_code = \"config = config_util.get_configs_from_pipeline_file(files[\\\"PIPELINE_CONFIG\\\"])\\nconfig\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = config_util.get_configs_from_pipeline_file(files[\"PIPELINE_CONFIG\"])\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\\nwith tf.io.gfile.GFile(files[\\\"PIPELINE_CONFIG\\\"], \\\"r\\\") as f:\\n    proto_str = f.read()\\n    text_format.Merge(proto_str, pipeline_config)\";\n",
       "                var nbb_formatted_code = \"pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\\nwith tf.io.gfile.GFile(files[\\\"PIPELINE_CONFIG\\\"], \\\"r\\\") as f:\\n    proto_str = f.read()\\n    text_format.Merge(proto_str, pipeline_config)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files[\"PIPELINE_CONFIG\"], \"r\") as f:\n",
    "    proto_str = f.read()\n",
    "    text_format.Merge(proto_str, pipeline_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"pipeline_config.model.ssd.num_classes = len(labels)\\npipeline_config.train_config.batch_size = 4\\npipeline_config.train_config.fine_tune_checkpoint = os.path.join(\\n    paths[\\\"PRETRAINED_MODEL_PATH\\\"], PRETRAINED_MODEL_NAME, \\\"checkpoint\\\", \\\"ckpt-0\\\"\\n)\\npipeline_config.train_config.fine_tune_checkpoint_type = \\\"detection\\\"\\npipeline_config.train_input_reader.label_map_path = files[\\\"LABELMAP\\\"]\\npipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [\\n    os.path.join(paths[\\\"DATA_PATH\\\"], \\\"train.record\\\")\\n]\\npipeline_config.eval_input_reader[0].label_map_path = files[\\\"LABELMAP\\\"]\\npipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [\\n    os.path.join(paths[\\\"DATA_PATH\\\"], \\\"test.record\\\")\\n]\";\n",
       "                var nbb_formatted_code = \"pipeline_config.model.ssd.num_classes = len(labels)\\npipeline_config.train_config.batch_size = 4\\npipeline_config.train_config.fine_tune_checkpoint = os.path.join(\\n    paths[\\\"PRETRAINED_MODEL_PATH\\\"], PRETRAINED_MODEL_NAME, \\\"checkpoint\\\", \\\"ckpt-0\\\"\\n)\\npipeline_config.train_config.fine_tune_checkpoint_type = \\\"detection\\\"\\npipeline_config.train_input_reader.label_map_path = files[\\\"LABELMAP\\\"]\\npipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [\\n    os.path.join(paths[\\\"DATA_PATH\\\"], \\\"train.record\\\")\\n]\\npipeline_config.eval_input_reader[0].label_map_path = files[\\\"LABELMAP\\\"]\\npipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [\\n    os.path.join(paths[\\\"DATA_PATH\\\"], \\\"test.record\\\")\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_config.model.ssd.num_classes = len(labels)\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(\n",
    "    paths[\"PRETRAINED_MODEL_PATH\"], PRETRAINED_MODEL_NAME, \"checkpoint\", \"ckpt-0\"\n",
    ")\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path = files[\"LABELMAP\"]\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [\n",
    "    os.path.join(paths[\"DATA_PATH\"], \"train.record\")\n",
    "]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files[\"LABELMAP\"]\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [\n",
    "    os.path.join(paths[\"DATA_PATH\"], \"test.record\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"config_text = text_format.MessageToString(pipeline_config)\\nwith tf.io.gfile.GFile(files[\\\"PIPELINE_CONFIG\\\"], \\\"wb\\\") as f:\\n    f.write(config_text)\";\n",
       "                var nbb_formatted_code = \"config_text = text_format.MessageToString(pipeline_config)\\nwith tf.io.gfile.GFile(files[\\\"PIPELINE_CONFIG\\\"], \\\"wb\\\") as f:\\n    f.write(config_text)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config_text = text_format.MessageToString(pipeline_config)\n",
    "with tf.io.gfile.GFile(files[\"PIPELINE_CONFIG\"], \"wb\") as f:\n",
    "    f.write(config_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': ssd {\n",
       "   num_classes: 2\n",
       "   image_resizer {\n",
       "     fixed_shape_resizer {\n",
       "       height: 320\n",
       "       width: 320\n",
       "     }\n",
       "   }\n",
       "   feature_extractor {\n",
       "     type: \"ssd_mobilenet_v2_fpn_keras\"\n",
       "     depth_multiplier: 1.0\n",
       "     min_depth: 16\n",
       "     conv_hyperparams {\n",
       "       regularizer {\n",
       "         l2_regularizer {\n",
       "           weight: 3.9999998989515007e-05\n",
       "         }\n",
       "       }\n",
       "       initializer {\n",
       "         random_normal_initializer {\n",
       "           mean: 0.0\n",
       "           stddev: 0.009999999776482582\n",
       "         }\n",
       "       }\n",
       "       activation: RELU_6\n",
       "       batch_norm {\n",
       "         decay: 0.996999979019165\n",
       "         scale: true\n",
       "         epsilon: 0.0010000000474974513\n",
       "       }\n",
       "     }\n",
       "     use_depthwise: true\n",
       "     override_base_feature_extractor_hyperparams: true\n",
       "     fpn {\n",
       "       min_level: 3\n",
       "       max_level: 7\n",
       "       additional_layer_depth: 128\n",
       "     }\n",
       "   }\n",
       "   box_coder {\n",
       "     faster_rcnn_box_coder {\n",
       "       y_scale: 10.0\n",
       "       x_scale: 10.0\n",
       "       height_scale: 5.0\n",
       "       width_scale: 5.0\n",
       "     }\n",
       "   }\n",
       "   matcher {\n",
       "     argmax_matcher {\n",
       "       matched_threshold: 0.5\n",
       "       unmatched_threshold: 0.5\n",
       "       ignore_thresholds: false\n",
       "       negatives_lower_than_unmatched: true\n",
       "       force_match_for_each_row: true\n",
       "       use_matmul_gather: true\n",
       "     }\n",
       "   }\n",
       "   similarity_calculator {\n",
       "     iou_similarity {\n",
       "     }\n",
       "   }\n",
       "   box_predictor {\n",
       "     weight_shared_convolutional_box_predictor {\n",
       "       conv_hyperparams {\n",
       "         regularizer {\n",
       "           l2_regularizer {\n",
       "             weight: 3.9999998989515007e-05\n",
       "           }\n",
       "         }\n",
       "         initializer {\n",
       "           random_normal_initializer {\n",
       "             mean: 0.0\n",
       "             stddev: 0.009999999776482582\n",
       "           }\n",
       "         }\n",
       "         activation: RELU_6\n",
       "         batch_norm {\n",
       "           decay: 0.996999979019165\n",
       "           scale: true\n",
       "           epsilon: 0.0010000000474974513\n",
       "         }\n",
       "       }\n",
       "       depth: 128\n",
       "       num_layers_before_predictor: 4\n",
       "       kernel_size: 3\n",
       "       class_prediction_bias_init: -4.599999904632568\n",
       "       share_prediction_tower: true\n",
       "       use_depthwise: true\n",
       "     }\n",
       "   }\n",
       "   anchor_generator {\n",
       "     multiscale_anchor_generator {\n",
       "       min_level: 3\n",
       "       max_level: 7\n",
       "       anchor_scale: 4.0\n",
       "       aspect_ratios: 1.0\n",
       "       aspect_ratios: 2.0\n",
       "       aspect_ratios: 0.5\n",
       "       scales_per_octave: 2\n",
       "     }\n",
       "   }\n",
       "   post_processing {\n",
       "     batch_non_max_suppression {\n",
       "       score_threshold: 9.99999993922529e-09\n",
       "       iou_threshold: 0.6000000238418579\n",
       "       max_detections_per_class: 100\n",
       "       max_total_detections: 100\n",
       "       use_static_shapes: false\n",
       "     }\n",
       "     score_converter: SIGMOID\n",
       "   }\n",
       "   normalize_loss_by_num_matches: true\n",
       "   loss {\n",
       "     localization_loss {\n",
       "       weighted_smooth_l1 {\n",
       "       }\n",
       "     }\n",
       "     classification_loss {\n",
       "       weighted_sigmoid_focal {\n",
       "         gamma: 2.0\n",
       "         alpha: 0.25\n",
       "       }\n",
       "     }\n",
       "     classification_weight: 1.0\n",
       "     localization_weight: 1.0\n",
       "   }\n",
       "   encode_background_as_zeros: true\n",
       "   normalize_loc_loss_by_codesize: true\n",
       "   inplace_batchnorm_update: true\n",
       "   freeze_batchnorm: false\n",
       " },\n",
       " 'train_config': batch_size: 4\n",
       " data_augmentation_options {\n",
       "   random_horizontal_flip {\n",
       "   }\n",
       " }\n",
       " data_augmentation_options {\n",
       "   random_crop_image {\n",
       "     min_object_covered: 0.0\n",
       "     min_aspect_ratio: 0.75\n",
       "     max_aspect_ratio: 3.0\n",
       "     min_area: 0.75\n",
       "     max_area: 1.0\n",
       "     overlap_thresh: 0.0\n",
       "   }\n",
       " }\n",
       " sync_replicas: true\n",
       " optimizer {\n",
       "   momentum_optimizer {\n",
       "     learning_rate {\n",
       "       cosine_decay_learning_rate {\n",
       "         learning_rate_base: 0.07999999821186066\n",
       "         total_steps: 50000\n",
       "         warmup_learning_rate: 0.026666000485420227\n",
       "         warmup_steps: 1000\n",
       "       }\n",
       "     }\n",
       "     momentum_optimizer_value: 0.8999999761581421\n",
       "   }\n",
       "   use_moving_average: false\n",
       " }\n",
       " fine_tune_checkpoint: \"/cache/home/ryd4/DeepRoute/pre-trained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0\"\n",
       " num_steps: 50000\n",
       " startup_delay_steps: 0.0\n",
       " replicas_to_aggregate: 8\n",
       " max_number_of_boxes: 100\n",
       " unpad_groundtruth_tensors: false\n",
       " fine_tune_checkpoint_type: \"detection\"\n",
       " fine_tune_checkpoint_version: V2,\n",
       " 'train_input_config': label_map_path: \"/cache/home/ryd4/DeepRoute/data/label_map.pbtxt\"\n",
       " tf_record_input_reader {\n",
       "   input_path: \"/cache/home/ryd4/DeepRoute/data/train.record\"\n",
       " },\n",
       " 'eval_config': metrics_set: \"coco_detection_metrics\"\n",
       " use_moving_averages: false,\n",
       " 'eval_input_configs': [label_map_path: \"/cache/home/ryd4/DeepRoute/data/label_map.pbtxt\"\n",
       " shuffle: false\n",
       " num_epochs: 1\n",
       " tf_record_input_reader {\n",
       "   input_path: \"/cache/home/ryd4/DeepRoute/data/test.record\"\n",
       " }\n",
       " ],\n",
       " 'eval_input_config': label_map_path: \"/cache/home/ryd4/DeepRoute/data/label_map.pbtxt\"\n",
       " shuffle: false\n",
       " num_epochs: 1\n",
       " tf_record_input_reader {\n",
       "   input_path: \"/cache/home/ryd4/DeepRoute/data/test.record\"\n",
       " }}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"config = config_util.get_configs_from_pipeline_file(files[\\\"PIPELINE_CONFIG\\\"])\\nconfig\";\n",
       "                var nbb_formatted_code = \"config = config_util.get_configs_from_pipeline_file(files[\\\"PIPELINE_CONFIG\\\"])\\nconfig\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = config_util.get_configs_from_pipeline_file(files[\"PIPELINE_CONFIG\"])\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 /cache/home/ryd4/DeepRoute/api_models/models/research/object_detection/model_main_tf2.py --model_dir=/cache/home/ryd4/DeepRoute/my_models/my_ssd_mobnet --pipeline_config_path=/cache/home/ryd4/DeepRoute/my_models/my_ssd_mobnet/pipeline.config --num_train_steps=2000\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"TRAINING_SCRIPT = os.path.join(\\n    paths[\\\"APIMODEL_PATH\\\"],\\n    \\\"models\\\",\\n    \\\"research\\\",\\n    \\\"object_detection\\\",\\n    \\\"model_main_tf2.py\\\",\\n)\\ncommand = \\\"python3 {} --model_dir={} --pipeline_config_path={} --num_train_steps=2000\\\".format(\\n    TRAINING_SCRIPT, paths[\\\"CHECKPOINT_PATH\\\"], files[\\\"PIPELINE_CONFIG\\\"]\\n)\\nprint(command)\";\n",
       "                var nbb_formatted_code = \"TRAINING_SCRIPT = os.path.join(\\n    paths[\\\"APIMODEL_PATH\\\"],\\n    \\\"models\\\",\\n    \\\"research\\\",\\n    \\\"object_detection\\\",\\n    \\\"model_main_tf2.py\\\",\\n)\\ncommand = \\\"python3 {} --model_dir={} --pipeline_config_path={} --num_train_steps=2000\\\".format(\\n    TRAINING_SCRIPT, paths[\\\"CHECKPOINT_PATH\\\"], files[\\\"PIPELINE_CONFIG\\\"]\\n)\\nprint(command)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TRAINING_SCRIPT = os.path.join(\n",
    "    paths[\"APIMODEL_PATH\"],\n",
    "    \"models\",\n",
    "    \"research\",\n",
    "    \"object_detection\",\n",
    "    \"model_main_tf2.py\",\n",
    ")\n",
    "command = \"python3 {} --model_dir={} --pipeline_config_path={} --num_train_steps=2000\".format(\n",
    "    TRAINING_SCRIPT, paths[\"CHECKPOINT_PATH\"], files[\"PIPELINE_CONFIG\"]\n",
    ")\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python /cache/home/ryd4/DeepRoute/api_models/models/research/object_detection/model_main_tf2.py --model_dir=/cache/home/ryd4/DeepRoute/my_models/my_ssd_mobnet --pipeline_config_path=/cache/home/ryd4/DeepRoute/my_models/my_ssd_mobnet/pipeline.config --checkpoint_dir=/cache/home/ryd4/DeepRoute/my_models/my_ssd_mobnet\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"\\ncommand = \\\"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\\\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])\\nprint(command)\";\n",
       "                var nbb_formatted_code = \"command = \\\"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\\\".format(\\n    TRAINING_SCRIPT,\\n    paths[\\\"CHECKPOINT_PATH\\\"],\\n    files[\\\"PIPELINE_CONFIG\\\"],\\n    paths[\\\"CHECKPOINT_PATH\\\"],\\n)\\nprint(command)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(\n",
    "    TRAINING_SCRIPT,\n",
    "    paths[\"CHECKPOINT_PATH\"],\n",
    "    files[\"PIPELINE_CONFIG\"],\n",
    "    paths[\"CHECKPOINT_PATH\"],\n",
    ")\n",
    "print(command)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 deep-route",
   "language": "python",
   "name": "deep-route"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
